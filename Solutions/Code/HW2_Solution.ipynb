{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, cdist, squareform\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the fasta file\n",
    "sequences = []\n",
    "for item in SeqIO.parse(\"HW2.fas\", \"fasta\"):\n",
    "    # turn sequences into lists of integers\n",
    "    sequences.append([ord(x) for x in list(item.seq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "264\n"
     ]
    }
   ],
   "source": [
    "# print how many sequences we have\n",
    "print(len(sequences))\n",
    "\n",
    "# check if all sequences have the same length\n",
    "# print the length if yes\n",
    "if len({len(seq) for seq in sequences}) == 1:\n",
    "    print(len(sequences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find normalized (divided by the length of a sequence) pairwise Hamming distances\n",
    "matrix_of_normalized_hamming_distances = squareform(pdist(sequences, 'hamming'))\n",
    "\n",
    "# turn them into Hamming distances\n",
    "hamming_distance_matrix = (len(sequences[0])*matrix_of_normalized_hamming_distances).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "mds = MDS(n_components = 2, dissimilarity = \"precomputed\", random_state = 0)\n",
    "\n",
    "similarities = mds.fit_transform(hamming_distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(similarities[:, 0], similarities[:, 1], marker = \"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT: \n",
    "#   points <- data points (as a list of lists)\n",
    "#   k      <- number of clusters (as an integer)\n",
    "\n",
    "# OUTPUT: \n",
    "#   a list of labels that idetify to which cluster a point belongs   \n",
    "\n",
    "def kmeans_from_scratch(points, k = 5):\n",
    "\n",
    "    centroids_indeces = random.sample(range(len(points)), k)\n",
    "    centroids = [points[i] for i in centroids_indeces]\n",
    "\n",
    "    # for each point, we find distances between centrods and the point\n",
    "    # the result is a marrix of the size 120 rows by k columns\n",
    "    distances_to_centroids = cdist(points, centroids, 'euclidean')\n",
    "\n",
    "    # we label all points as 0,1,2,... depending on their closeness to a centroid\n",
    "    # axis = 1 as we go each time along a row,\n",
    "    # and choose an index at which minimum is achieved in the row\n",
    "    labels = np.argmin(distances_to_centroids, axis = 1)\n",
    "\n",
    "    while True:\n",
    "        # we calculate clusters' means\n",
    "        cluster_means = [0] * k\n",
    "        for the_label in range(k):\n",
    "            points_labeled_with_the_label = [element for count, element in enumerate(points) if labels[count] == the_label]\n",
    "            cluster_means[the_label] = np.mean(points_labeled_with_the_label, axis = 0) \n",
    "\n",
    "        # now we use cluster_means as centers of the clusters\n",
    "        # recalculate distances to the clusters' centers\n",
    "        # and relabel point if needed\n",
    "        centroids_new = [item.tolist() for item in cluster_means]\n",
    "        distances_to_centroids_new = cdist(points, centroids_new, 'euclidean')\n",
    "        labels_new = np.argmin(distances_to_centroids_new, axis = 1)\n",
    "        if (labels_new == labels).all():\n",
    "            return(labels)\n",
    "            break\n",
    "        else:\n",
    "            labels = labels_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = [item.tolist() for item in similarities]\n",
    "labels = kmeans_from_scratch(points, k = 5)    \n",
    "print(labels)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(similarities[:, 0], similarities[:, 1], marker = \"x\", c = labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
